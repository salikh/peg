// Copyright 2019 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package generator

import (
	"bytes"
	"fmt"
	"go/ast"
	goparser "go/parser"
	"go/printer"
	"go/token"
	"io/ioutil"
	"strconv"

	log "github.com/golang/glog"
	"github.com/salikh/peg/compat/runfiles"
	"github.com/salikh/peg/generator/astutil"
	"github.com/salikh/peg/generator/gogen"
	"github.com/salikh/peg/parser"
	"github.com/salikh/peg/parser/charclass"
)

// generator keeps the parsed grammar and other data pertaining to the PEG grammar.
type generator struct {
	// source is the raw source of the PEG.
	source string
	// pegTree is the raw parse tree of the PEG.
	pegTree *parser.Node
	// peg is the semantic tree of the PEG.
	*Grammar
	// packageName keeps the package name of the Go source file with user-provided types.
	packageName string
}

func (g *generator) ParseTree() *parser.Node {
	return g.pegTree
}

func New(source string) (*generator, error) {
	log.V(1).Infof("Grammar: [%s]", source)
	g := &generator{
		source: source,
	}
	r, err := Parse(source)
	if err != nil {
		return nil, fmt.Errorf("cannot parse grammar source: %s", err)
	}
	if log.V(5) {
		log.Infof("PEG AST:\n%v\n", r.Tree)
	}
	g.pegTree = r.Tree
	g.Grammar, err = ConvertGrammar2(g.pegTree)
	if err != nil {
		return nil, fmt.Errorf("error constructing semantic tree: %s", err)
	}
	return g, nil
}

// Generate returns a Go source text of the generated
// parser package. The generated package name is gen.
func (g *generator) Generate(packagename string) (string, error) {
	// The grammar source was parsed in New.
	// Now generate AST
	f := generateAST(g.Grammar, packagename)
	// Add the grammar source as a top-level comment.
	f.Doc = &ast.CommentGroup{
		List: []*ast.Comment{
			&ast.Comment{
				Text: "// DO NOT EDIT. AUTOGENERATED",
			},
			&ast.Comment{
				Text: "// Source grammar:",
			},
			&ast.Comment{
				Text: "/*\n" + g.source + "\n*/",
			},
		},
	}
	fset := token.NewFileSet()
	var buf bytes.Buffer
	//log.Infof("Resulting node: %s", astutil.Wrap(astutil.String(f)))
	config := printer.Config{Mode: printer.UseSpaces | printer.TabIndent, Tabwidth: 8}
	err := config.Fprint(&buf, fset, f)
	//log.Infof("imports = %v", len(f.Imports))
	if err != nil {
		return "", fmt.Errorf("error in config.Fprint: %s", err)
	}
	if log.V(5) {
		log.Infof("Generated parser source:\n%s", buf.String())
	}
	return buf.String(), nil
}

type identSubstitutor struct {
	was    string
	became string
}

func (v *identSubstitutor) Visit(node ast.Node) ast.Visitor {
	switch t := node.(type) {
	case *ast.Ident:
		if t == nil {
			log.Exitf("nil node!")
		}
		if t.Name == v.was {
			t.Name = v.became
		}
	}
	return v
}

func substituteIdent(node ast.Node, was, became string) {
	//log.Infof("substituteIdent(%v, %q, %q)", node, was, became)
	/*
		switch t := node.(type) {
		case *ast.GenDecl:
			// Assume just 1 decl 1 var per GenDecl
			switch tt := t.Specs[0].(type) {
			case *ast.ValueSpec:
				// FIXME: deep copy.
				if tt.Names[0].Name == was {
					tt.Names[0].Name = became
				}
			}
		default:
	*/
	v := &identSubstitutor{was, became}
	ast.Walk(v, node)
	/*
		}
	*/
}

type literalSubstitutor struct {
	kind   token.Token
	was    string
	became string
}

func (v *literalSubstitutor) Visit(node ast.Node) ast.Visitor {
	/*
		if node != nil {
			log.Infof("literalSubstitutor: visiting %s", reflect.TypeOf(node).String())
		}
	*/
	switch t := node.(type) {
	case *ast.BasicLit:
		if t.Value != v.was {
			break
		}
		//log.Infof("Found %s, kind %v", t.Value, t.Kind)
		if t.Kind != v.kind {
			break
		}
		//log.Infof("Substituting %q with %q", t.Value, v.became)
		t.Value = v.became
	}
	return v
}

func substituteLiteral(node ast.Node, kind token.Token, was, became string) {
	v := &literalSubstitutor{kind, was, became}
	ast.Walk(v, node)
}

type lateSubstitution struct {
	*ast.Ident
	rule string
}

var lateSubstitutions []lateSubstitution

type lateIdentSubstitutor struct {
	was      string
	ruleName string
}

func (v *lateIdentSubstitutor) Visit(node ast.Node) ast.Visitor {
	switch t := node.(type) {
	case *ast.Ident:
		if t == nil {
			log.Exitf("nil node!")
		}
		if t.Name == v.was {
			lateSubstitutions = append(lateSubstitutions,
				lateSubstitution{t, v.ruleName})
		}
	}
	return v
}

func lateSubstituteIdent(node ast.Node, was, ruleName string) {
	v := &lateIdentSubstitutor{was, ruleName}
	ast.Walk(v, node)
}

// ruleHandlers accumulates the mapping from rule names in the grammar
// to the name of generated handler functions.
var ruleHandlers = make(map[string]string)

// TODO(salikh): Encapsulate into generator.
// handlerIndices accumulates the mapping from the rule names to the assigned
// handler indices.
var handlerIndices = make(map[string]int)

func lateSubstitutionsDoIt(node ast.Node) {
	for _, l := range lateSubstitutions {
		handlerName, ok := ruleHandlers[l.rule]
		if !ok {
			log.Exitf("Internal error: the handler for rule %q has not been "+
				"generated.", l.rule)
		}
		l.Ident.Name = handlerName
	}
}

func makeParseFn(name string) *ast.FuncDecl {
	parseFunc := astutil.DupFuncDecl(parseTemplate)
	lateSubstituteIdent(parseFunc, "testHandler", name)
	return gogen.Func("Parse", gogen.FuncType(
		gogen.Fields(gogen.AField("source", gogen.Ident("string"))),
		gogen.Fields(gogen.Field(nil, gogen.Star(gogen.Ident("Result"))),
			gogen.Field(nil, gogen.Ident("error")))),
		// The top rule always has handler index 0.
		gogen.Stmts(fmt.Sprintf(`
  r := &Result{Source: source, Memo: make(map[int]map[int]*Node), NodeStack: make([]*Node, 0, 10)}
  w, err := apply(r, 0, %s, 0)
  if err != nil {
		return r, err
	}
	if w != len(source) {
		return r, fmt.Errorf("some characters remain unconsumed: %%q", source[w:])
	}
  return r, nil
`, name+"Handler"))...)

}

func MakeDotHandler(handlerName string) []ast.Decl {
	return []ast.Decl{gogen.DotHandler(handlerName)}
}

const literalConstLabel = "literal"

func MakeLiteralHandler(val, handlerName string) []ast.Decl {
	return []ast.Decl{gogen.LiteralHandler(handlerName, val)}
}

func MakeCharClassHandler(cc *charclass.CharClass, handlerName string) []ast.Decl {
	if cc.Special == "[:any:]" {
		return MakeDotHandler(handlerName)
	}
	return []ast.Decl{gogen.CharClassHandler(handlerName, cc)}
}

func MakePlusHandler(handlerName, subHandler string) []ast.Decl {
	return []ast.Decl{gogen.PlusHandler(handlerName, subHandler)}
}

func MakeQuestionHandler(handlerName, subHandler string) []ast.Decl {
	return []ast.Decl{gogen.QuestionHandler(handlerName, subHandler)}
}

var ruleHandlerLabel = "LiteralHandler"

func makeRuleHandler(name, handlerName string) []ast.Decl {
	hi := handlerIndices[name]
	return []ast.Decl{
		gogen.Func(handlerName, gogen.FuncType(
			gogen.Fields(gogen.AField("r", gogen.Star(gogen.Ident("Result"))),
				gogen.AField("pos", gogen.Ident("int"))),
			gogen.Fields(gogen.Field(nil, gogen.Ident("int")),
				gogen.Field(nil, gogen.Ident("error")))),
			gogen.Return(gogen.Call(gogen.Ident("apply"),
				gogen.Ident("r"), gogen.Ident("pos"), gogen.Ident(name+"Handler"), gogen.Int(strconv.FormatInt(int64(hi), 10)))),
		),
	}
}

func MakeStarHandler(handlerName, subHandler string) []ast.Decl {
	return []ast.Decl{gogen.StarHandler(handlerName, subHandler)}
}

func MakeTermsHandler(terms []*Term, handlerName string) []ast.Decl {
	//log.Infof("MakeTermsHandler: %s\n", terms)
	var group []string
	var r []ast.Decl
	if len(terms) == 0 {
		log.Exitf("0 rules in a group")
	}
	for i := 0; i < len(terms); i++ {
		term := terms[i]
		subhandlerLabel := handlerName + "_" + strconv.Itoa(i+1)
		group = append(group, subhandlerLabel)
		r = append(r, MakeTermHandler(term, subhandlerLabel)...)
	}
	r = append(r, MakeGroupHandler(group, handlerName)...)
	return r
}

// unQuote converts the captured literal string with framing quoted ''/""
// into the actual string.
func unQuote(s string) (string, error) {
	if s[0] == '"' {
		return strconv.Unquote(s)
	} else {
		return s[1 : len(s)-1], nil
	}
}

func MakeTermHandler(term *Term, handlerName string) []ast.Decl {
	switch {
	case term.Ident != "":
		return makeRuleHandler(term.Ident, handlerName)
	case term.Literal != "":
		return MakeLiteralHandler(term.Literal, handlerName)
	case term.CharClass != nil:
		// FIXME: use grammar field
		utf8Used = true
		unicodeUsed = true
		return MakeCharClassHandler(term.CharClass, handlerName)
	case term.Capture != nil:
		subHandler := handlerName + "_capture"
		r := MakeRHSHandler(subHandler, subHandler, term.Capture)
		return append(r, gogen.CaptureHandler(handlerName, subHandler))
	case term.Special != nil:
		switch term.Special.Rune {
		case '+':
			subHandler := handlerName + "_plus"
			r := MakeTermHandler(term.Special.Term, subHandler)
			return append(r, MakePlusHandler(handlerName, subHandler)...)
		case '?':
			subHandler := handlerName + "_question"
			r := MakeTermHandler(term.Special.Term, subHandler)
			return append(r, MakeQuestionHandler(handlerName, subHandler)...)
		case '*':
			subHandler := handlerName + "_star"
			r := MakeTermHandler(term.Special.Term, subHandler)
			return append(r, MakeStarHandler(handlerName, subHandler)...)
		default:
			log.Exitf("Handler for special:%s is NYI", term.Special)
		}
	case term.Pred != nil:
		subHandler := handlerName + "_pos"
		r := MakeTermHandler(term.Pred, subHandler)
		return append(r, MakePredicateHandler(handlerName, subHandler, true)...)
	case term.NegPred != nil:
		subHandler := handlerName + "_neg"
		r := MakeTermHandler(term.NegPred, subHandler)
		return append(r, MakePredicateHandler(handlerName, subHandler, false)...)
	case term.Parens != nil:
		subHandler := handlerName + "_paren"
		return MakeRHSHandler(handlerName, subHandler, term.Parens)
	default:
		log.Exitf("Handler for term %s is NYI", term)
	}
	log.Exitf("Should not be reached")
	return nil
}

func MakePredicateHandler(handlerName, subHandler string, positive bool) []ast.Decl {
	return []ast.Decl{gogen.PredicateHandler(handlerName, subHandler, !positive)}
}

func MakeGroupHandler(group []string, handlerName string) []ast.Decl {
	handler := astutil.DupFuncDecl(groupHandlerTemplate)
	l0 := handler.Body.List[0:3]
	l2 := handler.Body.List[6:7]
	lt := handler.Body.List[3:6]
	var l1 []ast.Stmt
	for _, subhandlerName := range group {
		l := astutil.DupStmtList(lt)
		// Substitution is only needed in the first line.
		substituteIdent(l[0], "LiteralHandler", subhandlerName)
		l1 = append(l1, l...)
	}
	handler.Body.List = append(append(l0, l1...), l2...)
	substituteIdent(handler, "GroupHandler", handlerName)
	return []ast.Decl{handler}
}

func MakeChoiceHandler(group []string, handlerName string) []ast.Decl {
	if len(group) == 0 {
		log.Exitf("Internal error, 0 choices in MakeChoiceHandler")
	}
	return []ast.Decl{gogen.ChoiceHandler(handlerName, group[0], group[1:]...)}
}

// Returns the handler name and its Go definition.
func makeRule(rule *Rule) []ast.Decl {
	ruleName := rule.Ident
	if ruleName == "" {
		log.Exitf("Internal error, rule name empty")
	}
	if rule.RHS == nil {
		log.Exitf("Internal error, rule RHS empty")
	}
	handlerName := ruleName + "Handler"
	ruleHandlers[ruleName] = handlerName
	return MakeRHSHandler(handlerName, ruleName, rule.RHS)
}

func MakeRHSHandler(handlerName, ruleName string, rhs *RHS) []ast.Decl {
	var r []ast.Decl
	var group []string
	count := 1
	for _, terms := range rhs.Terms {
		subhandlerLabel := ruleName + "_" + strconv.Itoa(count)
		r = append(r, MakeTermsHandler(terms, subhandlerLabel)...)
		group = append(group, subhandlerLabel)
		count++
	}
	r = append(r, MakeChoiceHandler(group, handlerName)...)
	return r
}

func stripImport(f *ast.File, pkg string) {
	pkgLit := strconv.Quote(pkg)
	for i := 0; i < len(f.Imports); i++ {
		imp := f.Imports[i]
		if imp.Path.Value == pkgLit {
			for j := i; j < len(f.Imports)-1; j++ {
				f.Imports[j] = f.Imports[j+1]
			}
			f.Imports = f.Imports[:len(f.Imports)-1]
			break
		}
	}
	for _, decl := range f.Decls {
		if genDecl, ok := decl.(*ast.GenDecl); ok {
			if genDecl.Tok != token.IMPORT {
				continue
			}
			i := 0
			var spec ast.Spec
			for i, spec = range genDecl.Specs {
				if impSpec, ok := spec.(*ast.ImportSpec); ok {
					if impSpec.Path.Value == pkgLit {
						break
					}
				}
			}
			if i < len(genDecl.Specs) {
				for j := i; j < len(genDecl.Specs)-1; j++ {
					genDecl.Specs[j] = genDecl.Specs[j+1]
				}
				genDecl.Specs = genDecl.Specs[:len(genDecl.Specs)-1]
			}
		}
	}
}

type selectorVisitor struct {
	Name  string
	Found bool
}

func (v *selectorVisitor) Visit(n ast.Node) ast.Visitor {
	if selExpr, ok := n.(*ast.SelectorExpr); ok {
		if ident, ok := selExpr.X.(*ast.Ident); ok {
			if ident.Name == v.Name {
				v.Found = true
			}
		}
	}
	return v
}

func isPackageUsed(pkg string, tree *ast.File) bool {
	visitor := &selectorVisitor{Name: "utf8"}
	ast.Walk(visitor, tree)
	return visitor.Found
}

func generateAST(g *Grammar, packagename string) *ast.File {
	utf8Used = false // FIXME
	nf := astutil.DupFile(template)
	top := g.RuleNames[0]
	var labels []ast.Expr
	// Assign handler indices
	for hi, ruleName := range g.RuleNames {
		labels = append(labels, gogen.String(`"`+ruleName+`"`))
		// Store handler and hi correspondence.
		handlerIndices[ruleName] = hi
	}
	for _, rule := range g.Rules {
		decls := makeRule(rule)
		nf.Decls = append(nf.Decls, decls...)
	}
	labelsDecl := gogen.Var("labels", nil, gogen.Composite(gogen.SliceType(gogen.Ident("string")), labels))
	parseFn := makeParseFn(top)
	nf.Decls = append(nf.Decls, labelsDecl, parseFn)
	lateSubstitutionsDoIt(nf)
	// FIXME: use g.utf8Used
	utf8visitor := &selectorVisitor{Name: "utf8"}
	ast.Walk(utf8visitor, nf)
	utf8Used := utf8visitor.Found
	if !utf8Used {
		stripImport(nf, "unicode/utf8")
	}
	uniVisitor := &selectorVisitor{Name: "unicode"}
	ast.Walk(uniVisitor, nf)
	unicodeUsed := uniVisitor.Found
	if !unicodeUsed {
		stripImport(nf, "unicode")
	}
	nf.Name = &ast.Ident{
		Name: packagename,
	}
	return nf
}

var (
	template                      *ast.File
	charClassHandlerTemplate      *ast.FuncDecl
	charClassFlagTemplate         *ast.GenDecl
	charClassMapTemplate          *ast.GenDecl
	charClassSourceTemplate       *ast.GenDecl
	choiceHandlerTemplate         *ast.FuncDecl
	dotHandlerTemplate            *ast.FuncDecl
	groupHandlerTemplate          *ast.FuncDecl
	labelsTemplate                *ast.GenDecl
	literalConstTemplate          *ast.GenDecl
	literalHandlerTemplate        *ast.FuncDecl
	parseTemplate                 *ast.FuncDecl
	plusHandlerTemplate           *ast.FuncDecl
	predicateNegativeFlagTemplate *ast.GenDecl
	predicateHandlerTemplate      *ast.FuncDecl
	questionHandlerTemplate       *ast.FuncDecl
	ruleHandlerTemplate           *ast.FuncDecl
	starHandlerTemplate           *ast.FuncDecl
	pegG                          parser.Grammar
	utf8Used                      = false
	unicodeUsed                   = false
)

type funcFinder struct {
	name string
	*ast.FuncDecl
}

func (v *funcFinder) Visit(node ast.Node) ast.Visitor {
	if v.FuncDecl != nil {
		return nil
	}
	switch t := node.(type) {
	case *ast.FuncDecl:
		if t.Name.Name == v.name {
			v.FuncDecl = t
			return nil
		}
	}
	return v
}

func cutFunction(f *ast.File, name string) *ast.FuncDecl {
	// First find the function declaration.
	v := &funcFinder{name: name}
	ast.Walk(v, f)
	if v.FuncDecl == nil {
		log.Exitf("Could not find function %s", name)
	}
	// Next remove the declaration from the tree.
	for i := range f.Decls {
		if f.Decls[i] == v.FuncDecl {
			//fmt.Printf("%s found at %d\n", name, i)
			for j := i; j < len(f.Decls)-1; j++ {
				f.Decls[j] = f.Decls[j+1]
			}
			f.Decls = f.Decls[0 : len(f.Decls)-1]
			break
		}
	}
	return v.FuncDecl
}

type genFinder struct {
	name string
	token.Token
	*ast.GenDecl
}

func (v *genFinder) Visit(node ast.Node) ast.Visitor {
	if v.GenDecl != nil {
		return nil
	}
	switch t := node.(type) {
	case *ast.GenDecl:
		if t.Tok != v.Token || len(t.Specs) != 1 {
			break
		}
		switch s := t.Specs[0].(type) {
		case *ast.ValueSpec:
			if len(s.Names) == 1 && s.Names[0].Name == v.name {
				v.GenDecl = t
				return nil
			}
		}
	}
	return v
}

func cutConst(f *ast.File, name string) *ast.GenDecl {
	v := &genFinder{name: name, Token: token.CONST}
	ast.Walk(v, f)
	if v.GenDecl == nil {
		log.Exitf("Could not find const %s", name)
	}
	for i := range f.Decls {
		if f.Decls[i] == v.GenDecl {
			for j := i; j < len(f.Decls)-1; j++ {
				f.Decls[j] = f.Decls[j+1]
			}
			f.Decls = f.Decls[0 : len(f.Decls)-1]
			break
		}
	}
	return v.GenDecl
}

func cutVar(f *ast.File, name string) *ast.GenDecl {
	v := &genFinder{name: name, Token: token.VAR}
	ast.Walk(v, f)
	if v.GenDecl == nil {
		log.Exitf("Could not find const %s", name)
	}
	for i := range f.Decls {
		if f.Decls[i] == v.GenDecl {
			for j := i; j < len(f.Decls)-1; j++ {
				f.Decls[j] = f.Decls[j+1]
			}
			f.Decls = f.Decls[0 : len(f.Decls)-1]
			break
		}
	}
	return v.GenDecl
}

// cutGroupHandlerTemplate removes the sections starting from IGNORE to END.
func cutGroupHandlerTemplate(fn *ast.FuncDecl) {
	// FIXME: use comments to detect cut points
	l := fn.Body.List
	fn.Body.List = append(l[0:3], l[12:15]...)
	fn.Body.List = append(fn.Body.List, l[21:22]...)
}

// cutTemplates extracts the templateable elements from the File tree,
// and returns back the tree with templateable elements removed.
func cutTemplates(f *ast.File) {
	parseTemplate = cutFunction(f, "Parse")

	labelsTemplate = cutVar(f, "labels")
	charClassHandlerTemplate = cutFunction(f, "CharClassHandler")
	// TODO(salikh): This is not used for templating, only for testing.
	cutFunction(f, "CharClassAlnumHandler")
	charClassFlagTemplate = cutConst(f, "charClassNegated")
	charClassMapTemplate = cutVar(f, "charClassMap")
	charClassSourceTemplate = cutConst(f, "charClassSource")
	choiceHandlerTemplate = cutFunction(f, "ChoiceHandler")
	dotHandlerTemplate = cutFunction(f, "DotHandler")
	groupHandlerTemplate = cutFunction(f, "GroupHandler")
	cutGroupHandlerTemplate(groupHandlerTemplate)
	literalConstTemplate = cutConst(f, "literal")
	literalHandlerTemplate = cutFunction(f, "LiteralHandler")
	plusHandlerTemplate = cutFunction(f, "PlusHandler")
	predicateNegativeFlagTemplate = cutConst(f, "predicateNegative")
	predicateHandlerTemplate = cutFunction(f, "PredicateHandler")
	questionHandlerTemplate = cutFunction(f, "QuestionHandler")
	ruleHandlerTemplate = cutFunction(f, "RuleHandler")
	starHandlerTemplate = cutFunction(f, "StarHandler")

	cutVar(f, "testHandler") // Throw out the value.
}

func init() {
	templateFilename := runfiles.Path("github.com/salikh/peg/generator/template/template.go")
	src, err := ioutil.ReadFile(templateFilename)
	if err != nil {
		log.Exitf("Error reading gen.go: %s", err)
	}
	fset := token.NewFileSet()
	template, err = goparser.ParseFile(fset, "gen.go", src, goparser.ParseComments)
	if err != nil {
		log.Exitf("Error parsing gen.go: %s", err)
	}
	cutTemplates(template)

	pegFilename := runfiles.Path("github.com/salikh/peg/generator/peg.peg")
	pegGrammar, err := ioutil.ReadFile(pegFilename)
	if err != nil {
		log.Exitf("Cannot open %q: %s", pegFilename, err)
	}
	pegG, err = parser.New(string(pegGrammar))
	if err != nil {
		log.Exitf("Internal error in peg.peg: %s", err)
	}
}
